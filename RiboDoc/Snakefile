configfile: "/data/config.yaml"


ribodoc_version = "0.9.0"


# Imports
from optparse import OptionParser
import gffutils
import re
import os


# Sets the number of threads for multi-threading steps
multi_threads_nbr = 3
mem_mb_resources = 10000
# mem_mb_resources = (workflow.cores/3)*3000
utr_threshold = "0.25"


# Sets paths for inside the container
local_path = "/data/"
ribodoc_tools = "/RiboDoc/RiboDoc/tools/"
snakemake_log_path = local_path + ".snakemake/log/"


# Wildcards definition
SAMPLES, = glob_wildcards(local_path + "fastq/{sample}.fastq.gz")
SAMPLES.sort()
BOWTIE2 = ["1","2","3","4","rev.1","rev.2"]
HISAT2 = ["1","2","3","4","5","6","7","8"]
LENGTHS = list(map(str,range(int(config['readsLength_min']),int(config['readsLength_max'])+1)))


# Strings with minimum and maximum read lengths to be used in file names
frag_length_S = "." + LENGTHS[0]
frag_length_L = "." + LENGTHS[0] + "-" + LENGTHS[len(LENGTHS)-1]


# Mean number of isoforms in the genome (for transcriptome multi-alignment parameter)
isoform_nbr = "10"

# Check if attributes specified by the user are present in the gff file
htseq_additional = ""
htseq_header = 'ID\t'
fields = "1,2"

f = open(local_path + "database/" + config['gff'],"r")
for l in f:
    is_name = re.search("^([^\t]+\t){8}.*" + config['gff_name_attribut'],l)
    if is_name:
        name_in_gff = True

        features_of_interest = [config['gff_cds_feature']]
        if config['UTR'] == "yes":
            features_of_interest.extend([config['gff_5UTR_feature'],config['gff_3UTR_feature']])

        htseq_additional = "--additional-attr " + config['gff_name_attribut']
        htseq_header = 'ID\tName\t'
        fields = "1,3"
        break
    else:
        name_in_gff = False

f.close()


rule all:
    input:
        # Call of make_fastqc rule
        expand(local_path + "RESULTS/fastqc/fastqc_before_trimming/{sample}_fastqc.html", sample=SAMPLES),
        expand(local_path + "RESULTS/fastqc/fastqc_after_trimming/{sample}.cutadapt" + frag_length_L + "_fastqc.html", sample=SAMPLES),
        expand(local_path + "RESULTS/fastqc/make_fastqc_after_outRNA_depletion/{sample}" + frag_length_L + ".no-outRNA_fastqc.html", sample=SAMPLES) if config['fasta_outRNA']=="" else expand(local_path + "RESULTS/fastqc/fastqc_after_trimming/{sample}.cutadapt" + frag_length_L + "_fastqc.html", sample=SAMPLES),

        # Folder with main outputs
        local_path + "MAIN_RESULTS/" + config['project_name'] + ".Analysis_Report" + frag_length_L + ".txt"

# When RiboDoc starts
onstart:
    # In case the user is using a Macintosh computer, hidden files are removed
    shell("find " + local_path + " -depth -name '.DS_Store' -exec rm -f {{}} \;")
    shell("find " + local_path + " -depth -name '.AppleDouble' -exec rm -rf {{}} \;")
    shell("mkdir -p " + local_path + "logs/;")
    shell("echo 'RiboDoc version : " + ribodoc_version + "' > " + local_path + "logs/RiboDoc_package_versions.txt;")
    shell("conda list >> " + local_path + "logs/RiboDoc_package_versions.txt;")

# When the jobs are all done
onsuccess:
    # Copy config file to keep trace of parameters used
    shell("cp " + local_path + "config.yaml " + local_path + "RESULTS/;")
    # Remove useless directories if the pipeline does not stop because of an error
    shell("rm -f -r " + local_path + "RESULTS/qualitativeAnalysis/bedCount/ " + local_path + "RESULTS/qualitativeAnalysis/*tempoR.Rout;")
    shell("rm -f -r " + local_path + "RESULTS/no-outRNA/ " + local_path + "RESULTS/cutadapt/ " + local_path + "*tempoR.Rout;")
    shell("cp " + snakemake_log_path + "*.snakemake.log " + local_path + "logs/ || true;")

# If anything goes wrong
onerror:
    # Copy config file to keep trace of parameters used
    shell("cp " + local_path + "config.yaml " + local_path + "RESULTS/;")
    shell("cp .snakemake/log/*.snakemake.log " + local_path + "logs/ || true;")


# Find the adapter sequence if not set in config file
rule find_adapter_sequence:
    input:
        fastq = local_path + "fastq/{sample}.fastq.gz"
    output:
        adapter = local_path + "RESULTS/adapter_lists/{sample}.txt"
    log:
        rscript = local_path + "logs/find_adapter_sequence/{sample}.rscript.log",
        sed = local_path + "logs/find_adapter_sequence/{sample}.sed.log",
        echo = local_path + "logs/find_adapter_sequence/{sample}.echo.log",
        touch = local_path + "logs/find_adapter_sequence/{sample}.touch.log"
    shell:
        "touch {output.adapter} 2> {log.touch};"
        "if [ -z " + config['adapt_sequence'] + " ]; then "
        "Rscript " + ribodoc_tools + "find_adapter_sequence.R {input.fastq} 2> {log.rscript};"
        "elif [ '" + config['already_trimmed'] + "' = 'no' ]; then echo " + config['adapt_sequence'] + " 1> {output.adapter} 2> {log.echo};"
        "fi;"

# Adds transcript names and gene IDs to the CDS and exon lines if possible
rule name_CDS:
    input:
        gff = local_path + "database/" + os.path.basename(config['gff'])
    output:
        gff_namedCDS = local_path + "RESULTS/annex_database/NamedCDS_" + os.path.basename(config['gff'])
    run:
        gene_id_bool = True
        if name_in_gff == True:
            db = gffutils.create_db(input.gff, ':memory:', merge_strategy='create_unique', keep_order=True)
            with open(output.gff_namedCDS, 'w') as fout:
                for d in db.directives:
                    fout.write('##{0}\n'.format(d))
                for feature in db.all_features():
                    if feature.featuretype in features_of_interest or feature.featuretype == 'exon':
                        parent = list(db.parents(feature, level=1))
                        if len(parent) > 0:
                            parent = parent[0]
                            if parent.attributes.get(config['gff_name_attribut']) and not feature.attributes.get(config['gff_name_attribut']):
                                feature.attributes[config['gff_name_attribut']] = [i.replace("mRNA","cds") for i in parent.attributes.get(config['gff_name_attribut'])]
                                feature.attributes[config['gff_name_attribut']][0] + "_name"
                            if parent.attributes.get('ID') and not feature.attributes.get('ID'):
                                feature.attributes["ID"] = parent.attributes["ID"]
                                feature.attributes['ID'] = feature.attributes['ID'][0] + "_CDS"
                        if feature.attributes.get(config['gff_name_attribut']):
                            fout.write(str(feature) + ';\n')
                    else:
                        fout.write(str(feature) + '\n')
        else:
            shell("cp {input.gff} {output.gff_namedCDS};")
        if gene_id_bool:
            print("'gene_id' attributes are present.")
        else:
            print("Missing at least some 'gene_id' attribute in this gff.")
        shell("sed -i -E 's/\\s/\\t/8' {output.gff_namedCDS};")
        shell('sed -i -E "s/\\"//g" {output.gff_namedCDS};')

# Quality control of data : build of the fastqc on raw data
rule make_fastqc_before_trimming:
    input:
        local_path + "fastq/{sample}.fastq.gz"
    output:
        local_path + "RESULTS/fastqc/fastqc_before_trimming/{sample}_fastqc.zip",
        local_path + "RESULTS/fastqc/fastqc_before_trimming/{sample}_fastqc.html"
    log:
        local_path + "logs/make_fastqc_before_trimming/{sample}.log"
    benchmark:
        local_path + "benchmarks/make_fastqc_before_trimming/{sample}.benchmark.txt"
    params:
       outdir = local_path + "RESULTS/fastqc/fastqc_before_trimming/"
    shell:
        "fastqc {input} --outdir {params.outdir} 2> {log};"

# Removes/cuts potential adapters on the reads
rule adapt_trimming:
    input:
        fastq = local_path + "fastq/{sample}.fastq.gz",
        adapt_seq = local_path + "RESULTS/adapter_lists/{sample}.txt"
    output:
        cut_fastq = local_path + "RESULTS/cutadapt/{sample}.cutadapt" + frag_length_L + ".fastq.gz"
    log:
        trim_value = local_path + "logs/adapt_trimming/{sample}_trim_value.log",
        cutadapt = local_path + "logs/adapt_trimming/{sample}_cutadapt.log",
        cutadapt_out = local_path + "stats/{sample}_adapt_trimming.log"
    benchmark:
        local_path + "benchmarks/adapt_trimming/{sample}.benchmark.txt"
    resources:
        mem_mb = mem_mb_resources
    threads:
        multi_threads_nbr
    shell:
        "adapter_sequence=`cat {input.adapt_seq}`;"
        "if [ '" + config['already_trimmed'] + "' = 'no' ]; then trim=\"-a ${{adapter_sequence}} --trimmed-only\"; else trim=''; fi 2> {log.trim_value};"
        "cutadapt ${{trim}} -e 0.125 -j {threads} --max-n=1 -m " + config['readsLength_min'] + " -M " + config['readsLength_max'] + " -o {output.cut_fastq} {input.fastq} 1>> {log.cutadapt_out} 2> {log.cutadapt};"

# Quality control of data : build of the fastqc after adapter trimming
rule make_fastqc_after_trimming:
    input:
        local_path + "RESULTS/cutadapt/{sample}.cutadapt" + frag_length_L + ".fastq.gz"
    output:
        local_path + "RESULTS/fastqc/fastqc_after_trimming/{sample}.cutadapt" + frag_length_L + "_fastqc.zip",
        local_path + "RESULTS/fastqc/fastqc_after_trimming/{sample}.cutadapt" + frag_length_L + "_fastqc.html"
    log:
        local_path + "logs/make_fastqc_after_trimming/{sample}.log"
    benchmark:
        local_path + "benchmarks/make_fastqc_after_trimming/{sample}.benchmark.txt"
    params:
       outdir = local_path + "RESULTS/fastqc/fastqc_after_trimming/"
    shell:
        # fastqc 0.11.9
        "fastqc {input} --outdir {params.outdir} 2> {log};"

# Builds the index of bowtie2 mapping on sequences for reads remove
rule bowtie2_build_outRNA:
    input:
        outRNA = local_path + "database/" + os.path.basename(config['fasta_outRNA'])
    output:
        expand(local_path + "RESULTS/annex_database/outRNA_bowtie2.{extb}.bt2",extb=BOWTIE2)
    params:
        outNames = local_path + "RESULTS/annex_database/outRNA_bowtie2"
    log:
        local_path + "logs/bowtie2_build_outRNA/bowtie2_build_outRNA.log"
    benchmark:
        local_path + "benchmarks/bowtie2_build_outRNA/bowtie2_build_outRNA.benchmark.txt"
    threads:
        multi_threads_nbr
    shell:
        "bowtie2-build --threads {threads} {input.outRNA} {params.outNames} &> {log};"

# Mapping of non-coding RNA
rule bowtie2_run_outRNA:
    input:
        expand(local_path + "RESULTS/annex_database/outRNA_bowtie2.{extb}.bt2",extb=BOWTIE2),
        fastq = local_path + "RESULTS/cutadapt/{sample}.cutadapt" + frag_length_L + ".fastq.gz"
    output:
        local_path + "RESULTS/no-outRNA/{sample}" + frag_length_L + ".no-outRNA.fastq.gz"
    log:
        bt2 = local_path + "stats/{sample}_bowtie2_run_outRNA.log"
    benchmark:
        local_path + "benchmarks/bowtie2_run_outRNA/{sample}.benchmark.txt"
    resources:
        mem_mb = mem_mb_resources
    threads:
        multi_threads_nbr
    shell:
        "bowtie2 -x " + local_path + "RESULTS/annex_database/outRNA_bowtie2 --threads {threads} -U {input.fastq} --un-gz {output} > /dev/null 2>> {log.bt2};"

# Quality control of data : build of the fastqc after depletin rRNA as ribosomal RNA can have an impact on the data's profiles (ATGC content)
rule make_fastqc_after_outRNA_depletion:
    input:
        local_path + "RESULTS/no-outRNA/{sample}" + frag_length_L + ".no-outRNA.fastq.gz"
    output:
        local_path + "RESULTS/fastqc/make_fastqc_after_outRNA_depletion/{sample}" + frag_length_L + ".no-outRNA_fastqc.zip",
        local_path + "RESULTS/fastqc/make_fastqc_after_outRNA_depletion/{sample}" + frag_length_L + ".no-outRNA_fastqc.html"
    log:
        local_path + "logs/make_fastqc_after_outRNA_depletion/{sample}.log"
    benchmark:
        local_path + "benchmarks/make_fastqc_after_outRNA_depletion/{sample}.benchmark.txt"
    params:
       outdir = local_path + "RESULTS/fastqc/make_fastqc_after_outRNA_depletion/"
    shell:
        # fastqc 0.11.9
        "fastqc {input} --outdir {params.outdir} 2> {log};"

# Builds the index of bowtie2 mapping for all RNA
rule bowtie2_build:
    input:
        fasta = local_path + "database/" + os.path.basename(config['fasta'])
    output:
        expand(local_path + "RESULTS/annex_database/index_bowtie2.{extb}.bt2",extb=BOWTIE2)
    log:
        local_path + "logs/bowtie2_build/bowtie2_build.log"
    benchmark:
        local_path + "benchmarks/bowtie2_build/bowtie2_build.benchmark.txt"
    threads:
        multi_threads_nbr
    params:
        outNames = local_path + "RESULTS/annex_database/index_bowtie2"
    shell:
        "bowtie2-build --threads {threads} {input.fasta} {params.outNames} &> {log};"

# Builds the index of hisat2 mapping for all RNA
rule hisat2_build:
    input:
        fasta = local_path + "database/" + os.path.basename(config['fasta'])
    output:
        expand(local_path + "RESULTS/annex_database/index_hisat2.{exth}.ht2",exth=HISAT2)
    log:
        local_path + "logs/hisat2_build/hisat2_build.log"
    benchmark:
        local_path + "benchmarks/hisat2_build/hisat2_build.benchmark.txt"
    threads:
        multi_threads_nbr
    params:
        outNames = local_path + "RESULTS/annex_database/index_hisat2"
    shell:
        "hisat2-build --threads {threads} {input.fasta} {params.outNames} &> {log};"

# Mapping of all RNA by bowtie2 and hisat2
rule run_mapping:
    input:
        expand(local_path + "RESULTS/annex_database/index_hisat2.{exth}.ht2",exth=HISAT2),
        expand(local_path + "RESULTS/annex_database/index_bowtie2.{extb}.bt2",extb=BOWTIE2),
        fastq = local_path + "RESULTS/cutadapt/{sample}.cutadapt" + frag_length_L + ".fastq.gz" if config['fasta_outRNA']=="" else local_path + "RESULTS/no-outRNA/{sample}" + frag_length_L + ".no-outRNA.fastq.gz"
    output:
        fastq = temp(local_path + "RESULTS/no-outRNA/{sample}" + frag_length_L + ".no-outRNA.notAlign.fastq.gz"),
        sam_hisat2 = temp(local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".hisat2.sam"),
        sam_bowtie2 = temp(local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bowtie2.sam")
    log:
        hisat2_out = local_path + "stats/{sample}_run_mapping_hisat2.log",
        bowtie2_out = local_path + "stats/{sample}_run_mapping_bowtie2.log"
    benchmark:
        local_path + "benchmarks/run_mapping/{sample}.benchmark.txt"
    resources:
        mem_mb = mem_mb_resources
    params:
        index_names_hisat2 = local_path + "RESULTS/annex_database/index_hisat2",
        index_names_bowtie2 = local_path + "RESULTS/annex_database/index_bowtie2"
    threads:
        multi_threads_nbr
    shell:
        "hisat2 -x {params.index_names_hisat2} --threads {threads} --no-softclip -U {input.fastq} --un-gz {output.fastq} -S {output.sam_hisat2} 2>> {log.hisat2_out};"
        "bowtie2 -x {params.index_names_bowtie2} --threads {threads} --end-to-end -U {output.fastq} -S {output.sam_bowtie2} 2>> {log.bowtie2_out};"

# Creates bam and sam files
rule samtools_filter:
    input:
        sam_hisat2 = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".hisat2.sam",
        sam_bowtie2 = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bowtie2.sam"
    output:
        bam = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bam"
    log:
        grep_header_hisat2 = local_path + "logs/samtools_filter/{sample}.grep_hisat2.log",
        grep_core_hisat2 =  local_path + "logs/samtools_filter/{sample}.grep_core_hisat2.log",
        ZS_filter_hisat2 = local_path + "logs/samtools_filter/{sample}.NH_filter_hisat2.log",
        XM_filter_hisat2 = local_path + "logs/samtools_filter/{sample}.XM_filter_hisat2.log",
        grep_core_bowtie2 =  local_path + "logs/samtools_filter/{sample}.grep_core_bowtie2.log",
        XS_filter_bowtie2 = local_path + "logs/samtools_filter/{sample}.XS_filter_bowtie2.log",
        XM_filter_bowtie2 = local_path + "logs/samtools_filter/{sample}.XM_filter_bowtie2.log",
        view_bam = local_path + "logs/samtools_filter/{sample}.view_bam.log",
        sort_bam = local_path + "logs/samtools_filter/{sample}.sort_bam.log",
        rm = local_path + "logs/samtools_filter/{sample}.rm.log"
    benchmark:
        local_path + "benchmarks/samtools_filter/{sample}.benchmark.txt"
    resources:
        mem_mb = round(mem_mb_resources / 3)
    params:
        sam = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".sam"
    threads:
        multi_threads_nbr
    shell:
        "set +o pipefail;"
        "grep '^@' {input.sam_hisat2}  2> {log.grep_header_hisat2} 1> {params.sam};"
        "grep -v '^@' {input.sam_hisat2} 2> {log.grep_core_hisat2} | grep -v 'ZS:i:' 2> {log.ZS_filter_hisat2} | egrep -i 'XM:i:0|XM:i:1' 2> {log.XM_filter_hisat2} 1>> {params.sam};"
        "grep -v '^@' {input.sam_bowtie2} 2> {log.grep_core_bowtie2} | grep -v 'XS:i:' 2> {log.XS_filter_bowtie2} | egrep -i 'XM:i:0|XM:i:1' 2> {log.XM_filter_bowtie2} 1>> {params.sam};"
        "samtools view -@ {threads} -F 3844 -q 1 -h -b {params.sam} 2> {log.view_bam} | samtools sort -@ {threads} -o {output.bam} 2> {log.sort_bam};"
        "rm -rf {params.sam} 2> {log.rm};"

# Index BAMs
rule index_bam:
    input:
        bam = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bam"
    output:
        bai = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bam.bai"
    log:
        index_bam = local_path + "logs/index_bam/{sample}.index_bam.log"
    benchmark:
        local_path + "benchmarks/index_bam/{sample}.benchmark.txt"
    shell:
        "samtools index {input.bam} 2> {log.index_bam};"

# Creates an analysis report with trimming and alignment statistics
rule stats_report:
    input:
        ready = expand(rules.samtools_filter.output, sample=SAMPLES)
    output:
        stat_report = local_path + "RESULTS/" + config['project_name'] + ".Analysis_Report" + frag_length_L + ".txt"
    run:
        # List of interesting logs to make the report
        if config['fasta_outRNA'] == "":
            logs_names = ["adapt_trimming","run_mapping_hisat2","run_mapping_bowtie2"]
        else:
            logs_names = ["adapt_trimming","bowtie2_run_outRNA","run_mapping_hisat2","run_mapping_bowtie2"]

        # File for the statistical report
        data_report = open(output.stat_report,"w")
        for sample in SAMPLES:
            # Data treatment report creation
            data_report.write("##################\n## NEXT SAMPLE ##\n##################\n\n\t" + sample + "\n")
            for log in logs_names:
                data_report.write("\n" + ("#" * (len(log)+6)) + "\n## " + log + " ##\n" + ("#" * (len(log)+6)) + "\n")
                logs_files = open(local_path + "stats/" + sample + "_" + log + ".log","r")
                # Keep only lines of interest from cutadapt report1,2
                i=-1
                if log=="adapt_trimming":
                    lines_to_read = range(19)
                    for position, line in enumerate(logs_files):
                        if position in lines_to_read:
                            data_report.write(line)
                        else:
                            break
                else:
                    for line in logs_files:
                        data_report.write(line)
                logs_files.close()
            data_report.write("\n\n\n")
        data_report.close()

# Counts reads on each transcript
rule htseqcount_cds:
    input:
        bam = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bam",
        bai = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bam.bai",
        gff = local_path + "RESULTS/annex_database/NamedCDS_" + os.path.basename(config['gff'])
    output:
        htseq_table = local_path + "RESULTS/htseqcount_" + config['gff_cds_feature'] + "/{sample}" + frag_length_L + ".no-outRNA.htseqcount_" + config['gff_cds_feature'] + ".txt"
    log:
        echo = local_path + "logs/htseqcount_cds/{sample}.echo.log",
        sed = local_path + "logs/htseqcount_cds/{sample}.sed.log",
        htseqcount = local_path + "logs/htseqcount_cds/{sample}.htseqcount.log",
        head = local_path + "logs/htseqcount_cds/{sample}.head.log",
        awk = local_path + "logs/htseqcount_cds/{sample}.awk.log"
    benchmark:
        local_path + "benchmarks/htseqcount_cds/{sample}.benchmark.txt"
    params:
        tmp_file = local_path + "RESULTS/htseqcount_" + config['gff_cds_feature'] + "/{sample}_tmp.txt"
    threads:
        multi_threads_nbr
    shell:
        "set +o pipefail;"
        "echo -e '" + htseq_header + "' 2> {log.echo} > {output.htseq_table};"
        "sed -i '1s/$/{wildcards.sample}/' {output.htseq_table} 2> {log.sed};"
        "htseq-count -n {threads} -f bam -t " + config['gff_cds_feature'] + " -i "  + config['gff_parent_attribut'] + " " + htseq_additional + " -m intersection-strict --nonunique fraction {input.bam} {input.gff} 2> {log.htseqcount} > {params.tmp_file};"
        """head -n -5 {params.tmp_file} 2> {log.head} | awk -F '\t+' '{{if($3 >= 0) {{print($0)}} else {{printf("%s\\tNA\\t%s\\n",$1,$2)}}}}' 2> {log.awk} >> {output.htseq_table};"""
        "rm -f {params.tmp_file};"

# Counts reads on each 5prime, 3prime or CDS part of each transcript
rule htseqcount_utr:
    input:
        bam = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bam",
        bai = local_path + "RESULTS/BAM" + frag_length_L + "/{sample}" + frag_length_L + ".bam.bai",
        gff = local_path + "RESULTS/annex_database/NamedCDS_" + os.path.basename(config['gff']),
        htseqcount_cds = rules.htseqcount_cds.output
    output:
        htseq_table_threeprime = local_path + "RESULTS/htseqcount_" + config['gff_3UTR_feature'] + "/{sample}" + frag_length_L + ".no-outRNA.htseqcount_" + config['gff_3UTR_feature'] + ".txt",
        htseq_table_fiveprime = local_path + "RESULTS/htseqcount_" + config['gff_5UTR_feature'] + "/{sample}" + frag_length_L + ".no-outRNA.htseqcount_" + config['gff_5UTR_feature'] + ".txt"
    log:
        htseqcount_5prime = local_path + "logs/htseqcount_utr/{sample}.htseqcount_5prime.log",
        head_5prime = local_path + "logs/htseqcount_utr/{sample}.head_5prime.log",
        awk_5prime = local_path + "logs/htseqcount_utr/{sample}.awk_5prime.log",
        htseqcount_3prime = local_path + "logs/htseqcount_utr/{sample}.htseqcount_3prime.log",
        head_3prime = local_path + "logs/htseqcount_utr/{sample}.head_3prime.log",
        awk_3prime = local_path + "logs/htseqcount_utr/{sample}.awk_3prime.log"
    benchmark:
        local_path + "benchmarks/htseqcount_utr/{sample}.benchmark.txt"
    params:
        tmp_file = local_path + "RESULTS/{sample}_tmp.txt"
    threads:
        multi_threads_nbr
    shell:
        "set +o pipefail;"

        "echo -e 'ID\\tName\\t{wildcards.sample}' > {output.htseq_table_fiveprime};"
        "htseq-count -n {threads} -f bam -t " + config['gff_5UTR_feature'] + " -i "  + config['gff_parent_attribut'] + " " + htseq_additional + " -m intersection-strict --nonunique fraction {input.bam} {input.gff} 2> {log.htseqcount_5prime} > {params.tmp_file};"
        """head -n -5 {params.tmp_file} 2> {log.head_5prime} | awk -F '\t+' '{{if($3 >= 0) {{print($0)}} else {{printf("%s\\tNA\\t%s\\n",$1,$2)}}}}' 2> {log.awk_5prime} >> {output.htseq_table_fiveprime};"""
        "rm -f {params.tmp_file};"

        "echo -e 'ID\\tName\\t{wildcards.sample}' > {output.htseq_table_threeprime};"
        "htseq-count -n {threads} -f bam -t " + config['gff_3UTR_feature'] + " -i "  + config['gff_parent_attribut'] + " " + htseq_additional + " -m intersection-strict --nonunique fraction {input.bam} {input.gff} 2> {log.htseqcount_3prime} > {params.tmp_file};"
        """head -n -5 {params.tmp_file} 2> {log.head_3prime} | awk -F '\t+' '{{if($3 >= 0) {{print($0)}} else {{printf("%s\\tNA\\t%s\\n",$1,$2)}}}}' 2> {log.awk_3prime} >> {output.htseq_table_threeprime};"""
        "rm -f {params.tmp_file};"

# Creates the row names (genes/transcript names) of the count matrix
rule count_matrix_initialization:
    input:
        ready = expand(rules.htseqcount_utr.output, sample=SAMPLES) if config['UTR']=="yes" else expand(rules.htseqcount_cds.output, sample=SAMPLES),
        counts = local_path + "RESULTS/htseqcount_" + config['gff_cds_feature'] + "/" + SAMPLES[0] + "" + frag_length_L + ".no-outRNA.htseqcount_" + config['gff_cds_feature'] + ".txt"
    output:
        transcript_list = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/names_correspondence_list.txt"
    log:
        header = "logs/count_matrix_initialization/head.log",
        cut = "logs/count_matrix_initialization/cut.log",
        sort = local_path + "logs/count_matrix_initialization/sort.log"
    benchmark:
        local_path + "benchmarks/count_matrix_initialization/count_matrix_initialization.benchmark.txt"
    run:
        shell("set +o pipefail;")
        if name_in_gff == True:
            shell("""
            echo -e 'ID\\tTranscript_name\\tGene_name' 2> {log.header} > {output.transcript_list};
            tail +2 {input.counts} | cut -f 1,2 2> {log.cut} | LC_COLLATE=C sort 2> {log.sort} >> {output.transcript_list};
            sed -i -E 's/\\t([^\\t]+)(-[0-9]{{3}})/\\t\\1\\2\\t\\1/' {output.transcript_list};
            sed -i -E 's/^([^\\t]+)\\t([^\t]+)$/\\1\\t\\2\\t\\2/' {output.transcript_list};
            """)
        else:
            shell("""
            echo -e 'ID' 2> {log.header} > {output.transcript_list};
            tail +2 {input.counts} | cut -f 1,2 2> {log.cut} | LC_COLLATE=C sort 2> {log.sort} >> {output.transcript_list};
            """)

# Adds the read counts of each sample to the matrix
rule count_matrix_creation:
    input:
        transcript_list = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/names_correspondence_list.txt"
    output:
        counts_matrix = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/count_matrix_by_transcript.csv"
    log:
        cut = local_path + "logs/count_matrix_creation/cut.log",
        cat_cds = local_path + "logs/count_matrix_creation/cat.log",
        join_utr = local_path + "logs/count_matrix_creation/join_utr.log"
    benchmark:
        local_path + "benchmarks/count_matrix_creation/count_matrix_creation.benchmark.txt"
    params:
        tmp_file = local_path + "RESULTS/tmp.txt"
    run:
        for region in features_of_interest:
            shell("cut -f 1 {input.transcript_list} 2> {log.cut} > " + local_path + "RESULTS/htseqcount_" + region + "/count_matrix_by_transcript.csv;")
            for sample in SAMPLES:
                if name_in_gff == True:
                    fields = "1,3"
                else:
                    fields = "1,2"
                shell("cut -f " + fields + " " + local_path + "RESULTS/htseqcount_" + region + "/" + sample + frag_length_L + ".no-outRNA.htseqcount_" + region + ".txt | LC_COLLATE=C join --header -t $'\t' " + local_path + "RESULTS/htseqcount_" + region + "/count_matrix_by_transcript.csv - > {params.tmp_file} 2>> {log.cut};")
                shell("cat {params.tmp_file} 1> " + local_path + "RESULTS/htseqcount_" + region + "/count_matrix_by_transcript.csv 2> {log.cat_cds};")
            shell("LC_COLLATE=C join --header -t $'\t' {params.tmp_file} {input.transcript_list} 1> " + local_path + "RESULTS/htseqcount_" + region + "/count_matrix_by_transcript.csv 2> {log.join_utr}")
            shell("rm -f {params.tmp_file};")
            if region == features_of_interest[0]:
                shell("cp " + local_path + "RESULTS/htseqcount_" + region + "/count_matrix_by_transcript.csv {output.counts_matrix}")

# Create a count matrix by transcript and a count matrix by gene
rule matrices_by_gene_or_transcript:
    input:
        transcript_list = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/names_correspondence_list.txt",
        counts_matrix = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/count_matrix_by_transcript.csv"
    output:
        by_gene = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_gene/count_matrix_by_gene.csv",
        by_transcript = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_transcript/count_matrix_by_transcript.csv"
    log:
        local_path + "logs/matrices_by_gene_or_transcript/matrices_creation.log"
    benchmark:
        local_path + "benchmarks/matrices_by_gene_or_transcript/matrices_creation.benchmark.txt"
    script:
        ribodoc_tools + "by_gene_or_trancript_count_matrices.R"

# Performs differential analysis
rule DESeq2_analysis_gene:
    input:
        by_gene = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_gene/count_matrix_by_gene.csv"
    output:
        complete = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_gene/gene_complete.csv",
        up = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_gene/gene_up.csv",
        down = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_gene/gene_down.csv",
        report = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_gene/" + config['project_name'] + ".Final_report.html"
    log:
        control = local_path + "logs/DESeq2_analysis_gene/header_control.log",
        deseq2 = local_path + "logs/DESeq2_analysis_gene/DESeq2_analysis.log"
    benchmark:
        local_path + "benchmarks/DESeq2_analysis_gene/DESeq2_analysis.benchmark.txt"
    params:
        reportPath = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_gene/",
        reportName = config['project_name'] + ".Final_report.html"
    shell:
        "set +o pipefail;"
        "Rscript -e \"rmarkdown::render('" + ribodoc_tools + "DESeq2_analysis_by_gene.Rmd', output_format='html_document', output_file='{params.reportName}', output_dir='{params.reportPath}', intermediates_dir = '{params.reportPath}')\" 2> {log.deseq2};"

rule DESeq2_analysis_transcript:
    input:
        by_transcript = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_transcript/count_matrix_by_transcript.csv"
    output:
        complete = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_transcript/transcript_complete.csv",
        up = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_transcript/transcript_up.csv",
        down = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_transcript/transcript_down.csv",
        report = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_transcript/" + config['project_name'] + ".Final_report.html"
    log:
        control = local_path + "logs/DESeq2_analysis_transcript/header_control.log",
        deseq2 = local_path + "logs/DESeq2_analysis_transcript/DESeq2_analysis.log"
    benchmark:
        local_path + "benchmarks/DESeq2_analysis_transcript/DESeq2_analysis.benchmark.txt"
    params:
        reportPath = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_transcript/",
        reportName = config['project_name'] + ".Final_report.html"
    shell:
        "set +o pipefail;"
        "Rscript -e \"rmarkdown::render('" + ribodoc_tools + "DESeq2_analysis_by_transcript.Rmd', output_format='html_document', output_file='{params.reportName}', output_dir='{params.reportPath}', intermediates_dir = '{params.reportPath}')\" 2> {log.deseq2};"


# Quality controls :
# Filter the transcripts to only keep those with a 5-prime UTR if there are enough of them
rule filter_by_5UTR:
    input:
        gff_namedCDS = local_path + "RESULTS/annex_database/NamedCDS_" + os.path.basename(config['gff'])
    output:
        gff_5UTR_filtered = local_path + "RESULTS/annex_database/gff_5UTR_filtered_" + os.path.basename(config['gff']),
        gff_features = local_path + "RESULTS/annex_database/gff_features_counts.txt"
    log:
        local_path + "logs/filter_by_5UTR/filtering.log"
    benchmark:
        local_path + "benchmarks/filter_by_5UTR/filtering.benchmark.txt"
    params:
        annex_path = local_path + "RESULTS/annex_database/"
    shell:
        "bash " + ribodoc_tools + "filter_5UTR.sh -g {input.gff_namedCDS} -o {output.gff_5UTR_filtered} -p {params.annex_path} -r " + config["gff_mRNA_feature"] + " -u " + config["gff_5UTR_feature"] + " -t " + utr_threshold + " 2> {log};"

# In case there are no UTRs in the original GFF, call for ORFget functions
rule ORFget:
    input:
        fasta = local_path + "database/" + os.path.basename(config['fasta']),
        gff = local_path + "RESULTS/annex_database/gff_5UTR_filtered_" + os.path.basename(config['gff'])
    output:
        fasta = local_path + "RESULTS/annex_database/transcriptome_elongated.nfasta",
        gff = local_path + "RESULTS/annex_database/transcriptome_elongated.gff",
        gff_with_genes = local_path + "RESULTS/annex_database/transcriptome_elongated_with_gene_features.gff"
    log:
        orf_get = local_path + "logs/ORFget/orf_get.log",
        mv = local_path + "logs/ORFget/mv.log",
        awk = local_path + "logs/ORFget/awk.log"
    benchmark:
        local_path + "benchmarks/ORFget/ORFget.benchmark.txt"
    params:
        path = local_path + "RESULTS/annex_database/transcriptome"
    shell:
        "python3 " + ribodoc_tools + "ORFget.py -fna {input.fasta} -gff {input.gff} -features_include " + config['gff_cds_feature'] + " -name_attribute " + config['gff_name_attribut'] + " -o {params.path} -type nucl -elongate 50 -check 2> {log.orf_get};"
        "mv {output.gff} {output.gff_with_genes} 2> {log.mv};"
        "awk '$3 !~ /gene/' {output.gff_with_genes} > {output.gff} 2> {log.awk};"

# Create GTF file for riboWaltz
rule transcriptome_construction_gtf:
    input:
        fasta = local_path + "RESULTS/annex_database/transcriptome_elongated.nfasta",
        gff_with_genes = local_path + "RESULTS/annex_database/transcriptome_elongated_with_gene_features.gff"
    output:
        fasta = local_path + "RESULTS/annex_database/transcriptome_elongated.exons_" + os.path.basename(config['fasta']),
        gtf = local_path + "RESULTS/annex_database/transcriptome_elongated.exons_" + os.path.basename(config['gff']) + ".gtf"
    log:
        samtools_index = local_path + "logs/transcriptome_construction_gtf/samtools_index.log",
        gffread_gtf = local_path + "logs/transcriptome_construction_gtf/gffread.log",
        sed = local_path + "logs/transcriptome_construction_gtf/sed.log",
        awk = local_path + "logs/transcriptome_construction_gtf/awk.log"
    benchmark:
        local_path + "benchmarks/transcriptome_construction_gtf/transcriptome_construction_gtf.benchmark.txt"
    params:
        tmp_gtf = local_path + "RESULTS/annex_database/transcriptome_elongated.exons_tmp.gtf"
    shell:
        "samtools faidx {input.fasta} 2> {log.samtools_index};"
        "gffread -F -T -w {output.fasta} -o {params.tmp_gtf} -g {input.fasta} {input.gff_with_genes} 2> {log.gffread_gtf};"
        "sed -i 's/description[^\;]*\;//' {params.tmp_gtf} 2>> {log.sed};"
        "sed -i 's/\\t[A-Z]*[_]*gene_segment\\t/\\ttranscript\\t/' {params.tmp_gtf} 2>> {log.sed};"
        """awk -F '\\t' '{{if(NF<=9) {{print($0);}} else {{for(field=1;field<9;field++) {{printf("%s\\t",$field);}} for(field=9;field<=NF;field++) {{printf("%s ",$field);}} printf("\\n");}}}}' {params.tmp_gtf} > {output.gtf} 2>> {log.awk};"""
        "rm -f {params.tmp_gtf};"
        "sed -i 's/\\s$//' {output.gtf} 2>> {log.sed};"

# Builds the index of bowtie2 mapping for all RNA
rule bowtie2_build_transcriptome:
    input:
        fasta = local_path + "RESULTS/annex_database/transcriptome_elongated.nfasta"
    output:
        expand(local_path + "RESULTS/annex_database/transcriptome_elongated.transcriptome_index_bowtie2.{extb}.bt2",extb=BOWTIE2)
    log:
        local_path + "logs/bowtie2_build_transcriptome/bowtie2_build.log"
    benchmark:
        local_path + "benchmarks/bowtie2_build_transcriptome/transcriptome_index_bowtie2.benchmark.txt"
    params:
        index_names = local_path + "RESULTS/annex_database/transcriptome_elongated.transcriptome_index_bowtie2"
    threads:
        multi_threads_nbr
    shell:
        "bowtie2-build --threads {threads} {input.fasta} {params.index_names} &> {log};"

# Builds the index of hisat2 mapping for all RNA
rule hisat2_build_transcriptome:
    input:
        fasta = local_path + "RESULTS/annex_database/transcriptome_elongated.nfasta"
    output:
        expand(local_path + "RESULTS/annex_database/transcriptome_elongated.transcriptome_index_hisat2.{exth}.ht2",exth=HISAT2)
    log:
        local_path + "logs/hisat2_build_transcriptome/hisat2_build.log"
    benchmark:
        local_path + "benchmarks/hisat2_build_transcriptome/hisat2_build_transcriptome.benchmark.txt"
    params:
        index_names = local_path + "RESULTS/annex_database/transcriptome_elongated.transcriptome_index_hisat2"
    threads:
        multi_threads_nbr
    shell:
        "hisat2-build --threads {threads} {input.fasta} {params.index_names} &> {log};"

# Performs mapping on transcriptome
rule run_mapping_transcriptome:
    input:
        expand(local_path + "RESULTS/annex_database/transcriptome_elongated.transcriptome_index_hisat2.{exth}.ht2",exth=HISAT2),
        expand(local_path + "RESULTS/annex_database/transcriptome_elongated.transcriptome_index_bowtie2.{extb}.bt2",extb=BOWTIE2),
        fastq = local_path + "RESULTS/cutadapt/{sample}.cutadapt" + frag_length_L + ".fastq.gz" if config['fasta_outRNA']=="" else local_path + "RESULTS/no-outRNA/{sample}" + frag_length_L + ".no-outRNA.fastq.gz"
    output:
        sam_hisat2 = temp(local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/{sample}" + frag_length_L + ".hisat2.sam"),
        sam_bowtie2 = temp(local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/{sample}" + frag_length_L + ".bowtie2.sam"),
        fastq = temp(local_path + "RESULTS/no-outRNA/{sample}" + frag_length_L + ".no-outRNA.notAlign.transcriptome.fastq.gz")
    log:
        hisat2_out = local_path + "logs/run_mapping_transcriptome/{sample}_run_mapping_transcriptome_hisat2.log",
        bowtie2_out = local_path + "logs/run_mapping_transcriptome/{sample}_run_mapping_transcriptome_bowtie2.log"
    benchmark:
        local_path + "benchmarks/run_mapping_transcriptome/{sample}.benchmark.txt"
    resources:
        mem_mb = mem_mb_resources
    params:
        index_names_hisat2 = local_path + "RESULTS/annex_database/transcriptome_elongated.transcriptome_index_hisat2",
        index_names_bowtie2 = local_path + "RESULTS/annex_database/transcriptome_elongated.transcriptome_index_bowtie2"
    threads:
        multi_threads_nbr
    shell:
        "hisat2 -x {params.index_names_hisat2} --threads {threads} -k " + isoform_nbr + " --no-softclip -U {input.fastq} --un-gz {output.fastq} -S {output.sam_hisat2} 2>> {log.hisat2_out};"
        "bowtie2 -x {params.index_names_bowtie2} --threads {threads} -k " + isoform_nbr + " --end-to-end -U {output.fastq} -S {output.sam_bowtie2} 2>> {log.bowtie2_out};"

# Creates bam and sam files
rule samtools_filter_transcriptome:
    input:
        sam_hisat2 = local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/{sample}" + frag_length_L + ".hisat2.sam",
        sam_bowtie2 = local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/{sample}" + frag_length_L + ".bowtie2.sam"
    output:
        bam = local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/transcriptome_elongated.{sample}" + frag_length_L + ".bam"
    log:
        grep_header_hisat2 = local_path + "logs/samtools_filter_transcriptome/{sample}.grep_hisat2.log",
        uniq_header = local_path + "logs/samtools_filter_transcriptome/{sample}.uniq_header.log",
        grep_core_hisat2 =  local_path + "logs/samtools_filter_transcriptome/{sample}.grep_core_hisat2.log",
        XM_filter_hisat2 = local_path + "logs/samtools_filter_transcriptome/{sample}.XM_filter_hisat2.log",
        XM_filter_bowtie2 = local_path + "logs/samtools_filter_transcriptome/{sample}.XM_filter_bowtie2.log",
        grep_core_bowtie2 =  local_path + "logs/samtools_filter_transcriptome/{sample}.grep_core_bowtie2.log",
        view_bam = local_path + "logs/samtools_filter_transcriptome/{sample}.view_bam.log",
        sort_bam = local_path + "logs/samtools_filter_transcriptome/{sample}.sort_bam.log"
    benchmark:
        local_path + "benchmarks/samtools_filter_transcriptome/{sample}.benchmark.txt"
    resources:
        mem_mb = round(mem_mb_resources / 3)
    params:
        sample = "{sample}",
        sam = local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/{sample}" + frag_length_L + ".sam"
    threads:
        multi_threads_nbr
    shell:
        "set +o pipefail;"
        "grep '^@' {input.sam_hisat2}  2> {log.grep_header_hisat2} | uniq 2> {log.uniq_header} 1> {params.sam};"
        "grep -v '^@' {input.sam_hisat2} 2> {log.grep_core_hisat2} | egrep -i 'XM:i:0|XM:i:1' 2> {log.XM_filter_hisat2} 1>> {params.sam};"
        "grep -v '^@' {input.sam_bowtie2} 2> {log.grep_core_bowtie2} | egrep -i 'XM:i:0|XM:i:1' 2> {log.XM_filter_bowtie2} 1>> {params.sam};"
        "samtools view -@ {threads} -F 3588 -h -b {params.sam} 2> {log.view_bam} | samtools sort -@ {threads} -o {output.bam} 2> {log.sort_bam};"
        "rm -f {params.sam};"

# Index BAMs
rule index_bam_transcriptome:
    input:
        bam = local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/transcriptome_elongated.{sample}" + frag_length_L + ".bam"
    output:
        bai = local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/transcriptome_elongated.{sample}" + frag_length_L + ".bam.bai"
    log:
        index_bam = local_path + "logs/index_bam_transcriptome/{sample}.index_bam.log"
    benchmark:
        local_path + "benchmarks/index_bam_transcriptome/{sample}.benchmark.txt"
    shell:
        "samtools index {input.bam} 2> {log.index_bam};"


# riboWaltz pipeline
# Performs qualitative analysis with riboWaltz
rule riboWaltz_transcriptome:
    input:
        transcriptome_gtf = local_path + "RESULTS/annex_database/transcriptome_elongated.exons_" + os.path.basename(config['gff']) + ".gtf",
        transcriptome_bam = expand(rules.index_bam_transcriptome.output, sample=SAMPLES)
    output:
        psite_table = local_path + "RESULTS/riboWaltz/psite_offset.csv",
        metaprofile = local_path + "RESULTS/riboWaltz/transcriptome_elongated." + SAMPLES[0] + "/metaprofile_psite_-" + config['window_utr'] + "+" + config['window_cds'] + ".tiff"
    log:
        periodicity = local_path + "logs/riboWaltz_transcriptome/riboWaltz.log"
    resources:
        mem_mb = mem_mb_resources
    benchmark:
        local_path + "benchmarks/riboWaltz_transcriptome/riboWaltz.benchmark.txt"
    shell:
        "touch {output.psite_table};"
        "Rscript " + ribodoc_tools + "periodicity_riboWaltz_transcriptome.R {input.transcriptome_gtf} 2> {log};"
        "rm -f " + local_path + "Rplots.pdf;"


# TRiP pipeline
# Divisions of SAM file according to read length and turns it into BAM
rule quality_controls_bamDivision:
    input:
        bam = local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/transcriptome_elongated.{sample}" + frag_length_L + ".bam",
        bai = local_path + "RESULTS/BAM_transcriptome" + frag_length_L + "/transcriptome_elongated.{sample}" + frag_length_L + ".bam.bai"
    output:
        bam = local_path + "RESULTS/qualitativeAnalysis/bamDivision/{sample}.{taille}.uniq.sort.bam",
        bai = local_path + "RESULTS/qualitativeAnalysis/bamDivision/{sample}.{taille}.uniq.sort.bam.bai"
    log:
        local_path + "logs/quality_controls_bamDivision/{sample}.{taille}.BamDivision.log"
    benchmark:
        local_path + "benchmarks/quality_controls_bamDivision/{sample}.{taille}.benchmark.txt"
    threads:
        multi_threads_nbr
    params:
        sample_names = "{sample}",
        read_length = "{taille}"
    shell:
        "bash " + ribodoc_tools + "BamDivision.sh -N {params.sample_names} -l {params.read_length} -B {input.bam} -T {threads} -o " + local_path + "RESULTS/qualitativeAnalysis/ 2> {log};"

# Creates bed files from fasta files
rule quality_controls_bedcount:
    input:
        bam = local_path + "RESULTS/qualitativeAnalysis/bamDivision/{sample}.{taille}.uniq.sort.bam",
        bai = local_path + "RESULTS/qualitativeAnalysis/bamDivision/{sample}.{taille}.uniq.sort.bam.bai",
        fasta = local_path + "RESULTS/annex_database/transcriptome_elongated.nfasta"
    output:
        sequenceBedCount = local_path + "RESULTS/qualitativeAnalysis/sequenceBedCount/{sample}.{taille}.count.sequence.bed",
        readsLengthRepartitionBed = temp(local_path + "RESULTS/qualitativeAnalysis/readsLengthRepartition/{sample}.{taille}.bed"),
        bed = temp(local_path + "RESULTS/qualitativeAnalysis/bedCount/{sample}.{taille}.count.bed")
    log:
        local_path + "logs/quality_controls_bedcount/{sample}.{taille}.readsLengthRepartition.log"
    benchmark:
        local_path + "benchmarks/quality_controls_bedcount/{sample}.{taille}.benchmark.txt"
    params:
        sample_names = "{sample}",
        read_length = "{taille}"
    shell:
        "bash " + ribodoc_tools + "readsLengthRepartition.sh -N {params.sample_names} -l {params.read_length} -F {input.fasta} -D " + local_path + "RESULTS/qualitativeAnalysis/bamDivision/ -O " + local_path + "RESULTS/qualitativeAnalysis/ 2> {log};"

# Outputs the number of reads on each reads length
rule quality_controls_readsLengthRepartition:
    input:
        expand(rules.quality_controls_bedcount.output.readsLengthRepartitionBed, sample=SAMPLES, taille=LENGTHS)
    output:
        local_path + "RESULTS/qualitativeAnalysis/readsLengthRepartition/{sample}.readsLengthRepartition.txt"
    log:
        wc = local_path + "logs/quality_controls_readsLengthRepartition/{sample}.wc.log",
        sed1 = local_path + "logs/quality_controls_readsLengthRepartition/{sample}.sed1.log",
        awk = local_path + "logs/quality_controls_readsLengthRepartition/{sample}.awk.log",
        sed2 = local_path + "logs/quality_controls_readsLengthRepartition/{sample}.sed2.log",
        head = local_path + "logs/quality_controls_readsLengthRepartition/{sample}.head.log"
    benchmark:
        local_path + "benchmarks/quality_controls_readsLengthRepartition/{sample}.benchmark.txt"
    params:
        path = local_path + "RESULTS/qualitativeAnalysis/readsLengthRepartition/",
        sample_names = "{sample}"
    shell:
        "set +o pipefail;"
        "wc -l {params.path}{params.sample_names}* 2> {log.wc} | sed 's/\./ /g' 2> {log.sed1} | awk -F ' ' '{{print $(NF-1),$1}}' 2> {log.awk} | sed 's/ /\\t/g' 2> {log.sed2} | head -n -1 2> {log.head}  > {output};"

# Looks how many reads start on each base to find if there is a periodicity signal
rule quality_controls_periodicity:
    input:
        readsLengthRepartitionBed = local_path + "RESULTS/qualitativeAnalysis/readsLengthRepartition/{sample}.{taille}.bed",
        bed = local_path + "RESULTS/qualitativeAnalysis/bedCount/{sample}.{taille}.count.bed",
        gff = local_path + "RESULTS/annex_database/transcriptome_elongated_with_gene_features.gff"
    output:
        start = local_path + "RESULTS/qualitativeAnalysis/periodicity/{sample}.{taille}.periodicity.start." + config['gff_cds_feature'] + ".-" + config['window_utr'] + "+" + config['window_cds'] + ".txt",
        stop = local_path + "RESULTS/qualitativeAnalysis/periodicity/{sample}.{taille}.periodicity.stop." + config['gff_cds_feature'] + ".-" + config['window_cds'] + "+" + config['window_utr'] + ".txt"
    log:
        start = local_path + "logs/quality_controls_periodicity/{sample}.{taille}.log",
        stop = local_path + "logs/quality_controls_periodicity/{sample}.{taille}.log"
    benchmark:
        local_path + "benchmarks/quality_controls_periodicity/{sample}.{taille}.benchmark.txt"
    params:
        sample_names = "{sample}",
        read_length = "{taille}"
    shell:
        "bash " + ribodoc_tools + "periodicity.sh -N {params.sample_names} -l {params.read_length} -G {input.gff} -D " + local_path + "RESULTS/qualitativeAnalysis/bedCount/ -p 'start' -t '" + config['gff_cds_feature'] + "' -m " + config['window_utr'] + " -M " + config['window_cds'] + " -r 'metagene' -O " + local_path + "RESULTS/qualitativeAnalysis/ 2> {log.start};"
        "bash " + ribodoc_tools + "periodicity.sh -N {params.sample_names} -l {params.read_length} -G {input.gff} -D " + local_path + "RESULTS/qualitativeAnalysis/bedCount/ -p 'stop' -t '" + config['gff_cds_feature'] + "' -m " + config['window_cds'] + " -M " + config['window_utr'] + " -r 'metagene' -O " + local_path + "RESULTS/qualitativeAnalysis/ 2> {log.stop};"

# Creates graphs of reads length repartition
rule graphs_length:
    input:
        length = rules.quality_controls_readsLengthRepartition.output
    output:
        length = local_path + "RESULTS/qualitativeAnalysis/graphes/readsLengthRepartition/{sample}.readsLengthRepartition.jpeg"
    params:
        sample_name = "{sample}"
    log:
        rscript = local_path + "logs/quality_controls_graphs_length/{sample}.rscript.log"
    benchmark:
        local_path + "benchmarks/quality_controls_graphs_length/{sample}.benchmark.txt"
    shell:
        "Rscript " + ribodoc_tools + "generationGraph_length.R --work_dir " + local_path + " --sample_name {params.sample_name} 2> {log.rscript}"

# Creates periodicity graphs
rule graphs_periodicity:
    input:
        perio = rules.quality_controls_periodicity.output
    output:
        perioStart = local_path + "RESULTS/qualitativeAnalysis/graphes/periodicity/{sample}.{taille}.periodicity.start." + config['gff_cds_feature'] + ".-" + config['window_utr'] + "+" + config['window_cds'] + ".jpeg",
        perioStop = local_path + "RESULTS/qualitativeAnalysis/graphes/periodicity/{sample}.{taille}.periodicity.stop." + config['gff_cds_feature'] + ".-" + config['window_cds'] + "+" + config['window_utr'] + ".jpeg"
    params:
        name_start = "{sample}.{taille}.periodicity.start." + config['gff_cds_feature'] + ".-" + config['window_utr'] + "+" + config['window_cds'],
        name_stop = "{sample}.{taille}.periodicity.stop." + config['gff_cds_feature'] + ".-" + config['window_cds'] + "+" + config['window_utr']
    log:
        start = local_path + "logs/quality_controls_graphs_periodicity/{sample}.{taille}.start.log",
        stop = local_path + "logs/quality_controls_graphs_periodicity/{sample}.{taille}.stop.log"
    benchmark:
        local_path + "benchmarks/quality_controls_graphs_periodicity/{sample}.{taille}.benchmark.txt"
    shell:
        "Rscript " + ribodoc_tools + "generationGraph_perio.R --work_dir " + local_path + " --name {params.name_start} --feature_type " + config['gff_cds_feature'] + " --start_or_stop 'start' --length_before '" + config['window_utr'] + "' 2> {log.start};"
        "Rscript " + ribodoc_tools + "generationGraph_perio.R --work_dir " + local_path + " --name {params.name_stop} --feature_type " + config['gff_cds_feature'] + " --start_or_stop 'stop' --length_before '" + config['window_cds'] + "' 2> {log.stop};"

# Creates periodicity graphs
rule main_output_folder:
    input:
        stats_report = local_path + "RESULTS/" + config['project_name'] + ".Analysis_Report" + frag_length_L + ".txt",
        deseq2_transcript = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_transcript/" + config['project_name'] + ".Final_report.html",
        deseq2_gene = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L + "/DESeq2_by_gene/" + config['project_name'] + ".Final_report.html",
        qualitative_lengths = local_path + "RESULTS/riboWaltz/psite_offset.csv" if config['qualitative_analysis']=="ribowaltz" else expand(rules.graphs_length.output,sample=SAMPLES,taille=LENGTHS),
        qualitative_perio = local_path + "RESULTS/riboWaltz/psite_offset.csv" if config['qualitative_analysis']=="ribowaltz" else expand(rules.graphs_periodicity.output,sample=SAMPLES,taille=LENGTHS)
    output:
        local_path + "MAIN_RESULTS/" + config['project_name'] + ".Analysis_Report" + frag_length_L + ".txt"
    params:
        deseq2_folder = local_path + "RESULTS/DESeq2_" + config['gff_cds_feature'] + frag_length_L,
        graphs_folder = local_path + "RESULTS/periodicity_-" + config['window_utr'] + "+" + config['window_cds'] if config['qualitative_analysis']=="ribowaltz" else local_path + "RESULTS/qualitativeAnalysis/graphes/periodicity/"
    log:
        bash = local_path + "logs/main_output_folder/bash.log"
    benchmark:
        local_path + "benchmarks/main_output_folder/benchmark.txt"
    shell:
        "bash " + ribodoc_tools + "main_results_folder_maker.sh -p " + local_path + " -P " + ribodoc_tools + " -q " + config['qualitative_analysis'] + " -d {params.deseq2_folder} -s {input.stats_report} -g {params.graphs_folder} 2> {log.bash};"
